{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g8XTWYGq1k1",
        "outputId": "d5086565-d712-40d5-b858-116084fe2f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwlKeY2cr_Mp",
        "outputId": "6796e4c1-54f9-47eb-ee4b-9a5c870a48b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.47.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.47.0-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.47.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "# Set the API key\n",
        "client = OpenAI(api_key=\"\")\n",
        "MODEL = \"gpt-4o\"\n",
        "\n",
        "# Load the .jsonl file\n",
        "input_file = '/content/drive/MyDrive/fine_tuning_const/output_data.jsonl'\n",
        "output_file = '/content/drive/MyDrive/fine_tuning_const/corrected.jsonl'\n",
        "# Function to correct spelling and generate a question\n",
        "def correct_and_generate_question(text):\n",
        "    # Correct spelling\n",
        "    correction_prompt = f\"Please correct the spelling and grammar in the following text: {text}\"\n",
        "    correction_response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": correction_prompt}\n",
        "        ]\n",
        "    )\n",
        "    corrected_text = correction_response.choices[0].message.content.strip()\n",
        "\n",
        "    # Generate a question\n",
        "    question_prompt = f\"Based on the following text, generate a question: {corrected_text}\"\n",
        "    question_response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": question_prompt}\n",
        "        ]\n",
        "    )\n",
        "    question = question_response.choices[0].message.content.strip()\n",
        "\n",
        "    return corrected_text, question\n",
        "\n",
        "# Process the .jsonl file\n",
        "with open(input_file, 'r', encoding='utf-8') as f, open(output_file, 'w', encoding='utf-8') as out_f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        system_response = data['messages'][0]['content']\n",
        "\n",
        "        # Correct the text and generate a question\n",
        "        corrected_response, question = correct_and_generate_question(system_response)\n",
        "\n",
        "        # Print corrected response and question\n",
        "        print(\"Corrected Response:\", corrected_response)\n",
        "        print(\"Generated Question:\", question)\n",
        "\n",
        "        # Update the data and write to the new .jsonl file\n",
        "        data['messages'][0]['content'] = corrected_response\n",
        "        data['question'] = question\n",
        "\n",
        "        out_f.write(json.dumps(data, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(\"Processing complete. Corrected file saved as:\", output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Cn5wnsyJtNJf",
        "outputId": "136090de-1b41-4f65-d605-a6d26b57e4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrected Response: Sure, the text \"نورتنا ! كيفاش نجم نعاونك؟\" is already correct in terms of spelling and grammar for Tunisian Arabic in informal communication. The literal translation in English would be \"You have enlightened us! How can I help you?\". \n",
            "\n",
            "If you need it to be in Modern Standard Arabic (MSA), it would be:\n",
            "\n",
            "\"نورتنا! كيف يمكنني مساعدتك؟\"\n",
            "\n",
            "Both versions are correctly spelled and grammatically correct for their respective forms of Arabic.\n",
            "Generated Question: What is the Modern Standard Arabic (MSA) translation of \"You have enlightened us! How can I help you?\" based on the given text?\n",
            "Corrected Response: The text appears to be in colloquial Arabic. Here is a corrected version of the text, aiming to maintain its informal tone:\n",
            "\n",
            "عالعينين يا غالي! كيفاش تنجّم نعاونك؟\n",
            "Generated Question: ما هو معنى العبارة \"عالعينين يا غالي\" في اللهجة العامية العربية؟\n",
            "Corrected Response: !شنوّة اللي تحب تعرف عليه؟\n",
            "Generated Question: شنوّة الأمور اللي حاب تعرفها أكثر؟\n",
            "Corrected Response: The text you provided is in Tunisian Arabic. It's already correct as is. The phrase \"عسلامة! كي نجم نعاونك؟\" translates to \"Hello! How can I help you?\" in English.\n",
            "\n",
            "If you have any further questions or need more corrections, feel free to ask!\n",
            "Generated Question: What is the English translation of the Tunisian Arabic phrase \"عسلامة! كي نجم نعاونك؟\"?\n",
            "Corrected Response: The text you provided is in Tunisian Arabic, and it translates to \"Hello! How can I help you?\" in English. The original text is already correct in its context. However, if you're looking for the Modern Standard Arabic equivalent, it would be:\n",
            "\n",
            "\"السلام عليكم! كيف يمكنني مساعدتك؟\"\n",
            "Generated Question: What is the Modern Standard Arabic equivalent of \"Hello! How can I help you?\"?\n",
            "Corrected Response: Certainly! The corrected text is: \"مرحبًا بك يا حبيبي! ما الذي على بالك؟\"\n",
            "Generated Question: What is the English translation of the corrected Arabic text: \"مرحبًا بك يا حبيبي! ما الذي على بالك؟\"\n",
            "Corrected Response: مرحبًا بك في أليرت! ماذا تحب أن تعرف؟\n",
            "Generated Question: ماذا يمكنني أن أتعلم من أليرت؟\n",
            "Corrected Response: صباح النور! شنوّة تحب تعرف؟\n",
            "Generated Question: صباح الخير! شنوّة المواضيع اللي ممكن تحكينا عليهم؟\n",
            "Corrected Response: The text \"شنوّة اللي تحب تسأل عليه؟\" is already correct in Tunisian Arabic. It translates to \"What do you want to ask about?\" in English. Adjusting the grammar or spelling isn't needed as it aligns with the norms and common usage in Tunisian dialect.\n",
            "Generated Question: What is the English translation of the Tunisian Arabic phrase \"شنوّة اللي تحب تسأل عليه؟\"?\n",
            "Corrected Response: الصحيح هو: \"صباح النور! شنو حبيت تعرف؟\"\n",
            "Generated Question: ما النص الصحيح لهذه العبارة: \"صباح النور! شنو حبيت تعرف؟\"؟\n",
            "Corrected Response: Sure, the text is in Arabic and is already written with correct spelling and grammar. However, it can be made more formal if necessary. Here is a slightly more formal version:\n",
            "\n",
            "يَا هَلا بِالَّذِي جَاءَنَا! كَيف تُحِبّ أَنْ أُسَاعِدَكَ؟\n",
            "Generated Question: كيف يمكنني مساعدتك بطريقة أفضل؟\n",
            "Corrected Response: Certainly! The corrected text is:\n",
            "\n",
            "! شنوّة اللي تحب تعرف عليه؟\n",
            "\n",
            "It appears to be a phrase in Arabic script. The text is grammatically correct in Arabic dialect, specifically Tunisian Arabic. If you need further assistance or translation, please let me know!\n",
            "Generated Question: What is the translation of the Tunisian Arabic phrase \"! شنوّة اللي تحب تعرف عليه؟\" into English?\n",
            "Corrected Response: ألو، سلام! كيف يمكنني مساعدتك؟\n",
            "Generated Question: كيف يمكنك مساعدتي في حل مشكلتي؟\n",
            "Corrected Response: مرحبًا بك في أليرت! فما حاجتك التي نستطيع خدمتها لك؟\n",
            "Generated Question: ما هي الخدمة التي تحتاج المساعدة فيها من أليرت؟\n",
            "Corrected Response: العيون وعلى الرأس! ماذا تريد أن تعرف؟\n",
            "Generated Question: ماذا أستطيع أن أفعل إذا زرت مصر لأول مرة؟\n",
            "Corrected Response: مرحباً بيك! شنوّة تحب تعرف؟\n",
            "Generated Question: ما هي أنواع المعلومات التي يمكنك تقديمها؟\n",
            "Corrected Response: The text you provided is in Tunisian Arabic, which uses a unique dialect with its own vocabulary and grammar. In standard Arabic, the phrase would be corrected to:\n",
            "\n",
            "ماذا تريد أن تعرف؟\n",
            "\n",
            "However, if you are communicating with someone who understands Tunisian Arabic, your original phrase \"شنوّة تحب تعرفه؟\" is perfectly understandable and appropriate.\n",
            "Generated Question: What is the correct standard Arabic translation for the Tunisian Arabic phrase \"شنوّة تحب تعرفه؟\"?\n",
            "Corrected Response: بَارك الله فيك! شنوّة اللي تحب تسأل عنه؟\n",
            "Generated Question: بَارك الله فيك! شنوّة اللي نجم نسألك عليه؟\n",
            "Corrected Response: أسعد الله صباحك! ماذا تريد أن تعرف؟\n",
            "Generated Question: ما الأشياء التي يمكنني تعلمها أو السؤال عنها اليوم؟\n",
            "Corrected Response: النص الذي قدمته مكتوب باللغة العربية الدارجة (العامية التونسية)، وعادةً لا يتطلب كتابة الدارجة تصحيحاً صارماً. إلا إذا كنت تفضل الكتابة باللغة العربية الفصحى. في هذه الحالة، يمكن تصحيح النص كالتالي:\n",
            "\n",
            "أهلاً وسهلاً! كيف يمكنني مساعدتك اليوم؟\n",
            "\n",
            "أرجو أن يكون هذا مفيداً. إذا كان لديك أي طلب آخر، فلا تتردد في طرحه.\n",
            "Generated Question: هل تفضل أن أقدم لك النص المكتوب باللغة العربية الدارجة أم باللغة العربية الفصحى؟\n",
            "Corrected Response: The text you provided is in Tunisian Arabic, and it translates to \"What do you want to know?\" in English. The spelling and grammar are appropriate for conversational Tunisian Arabic. However, if you are looking for a more formal Arabic version, it would be:\n",
            "\n",
            "ماذا تريد أن تعرف؟\n",
            "Generated Question: What is the translation of \"What do you want to know?\" into formal Arabic?\n",
            "Corrected Response: النص بالفعل صحيح من الناحية الإملائية والنحوية. العبارة باللهجة التونسية وتعني \"نورتنا! كيفاش نجم نعاونك؟\" وهي تُستخدم للترحيب وسؤال الشخص عن كيفية مساعدته. يمكن أن تكون الترجمة إلى اللغة العربية الفصحى: \"أنرتنا! كيف يمكنني مساعدتك؟\"\n",
            "Generated Question: ما هي الترجمة إلى اللغة العربية الفصحى لعبارة الترحيب التونسية \"نورتنا! كيفاش نجم نعاونك؟\"؟\n",
            "Corrected Response: صباح النور! شنو حبيت تعرف؟\n",
            "Generated Question: شنو المواضيع اللي ممكن نتكلم عنها اليوم؟\n",
            "Corrected Response: The text \"مساء الخير! كيفاش نجم نعاونك؟\" is perfectly correct in its spelling and grammar. It means \"Good evening! How can I help you?\" in Tunisian Arabic. If you need any further assistance or have any specific requests regarding grammar or spelling, please let me know!\n",
            "Generated Question: What is the English translation of the Tunisian Arabic phrase \"مساء الخير! كيفاش نجم نعاونك؟\"?\n",
            "Corrected Response: The text you've provided is in Tunisian Arabic and is a common greeting. However, if you want it to be in Modern Standard Arabic with correct spelling and grammar, it would be:\n",
            "\n",
            "السلام عليكم! كيف الأمور؟\n",
            "\n",
            "In this form, it says \"Peace be upon you! How are things?\"\n",
            "Generated Question: How do you say \"Peace be upon you! How are things?\" in Modern Standard Arabic?\n",
            "Corrected Response: نورتنا! كيفاش نجم نعاونك؟\n",
            "Generated Question: كيف يمكنني مساعدتك اليوم؟\n",
            "Corrected Response: The text \"شنوّة تحب تعرفه?\" is already correct in spelling and grammar in Tunisian Arabic, which translates to \"What do you want to know?\" in English.\n",
            "Generated Question: How do you ask \"What do you want to know?\" in Tunisian Arabic?\n",
            "Corrected Response: النص يبدو مكتوباً بشكل سليم من حيث اللغة العربية، ولكن هناك تعديل بسيط يمكن إضافته لتحسين الجودة النصية:\n",
            "\n",
            "مرحباً بزينة الدنيا! كيف تحب أن أساعدك؟\n",
            "Generated Question: ما هو التعديل البسيط الذي يمكن إضافته لتحسين الجودة النصية في العبارة: \"مرحباً بزينة الدنيا! كيف تحب أن أساعدك؟\"؟\n",
            "Corrected Response: ألو، مرحباً بك في أليرت! ماذا تحتاج؟\n",
            "Generated Question: ما الخدمات التي تقدمها شركة أليرت؟\n",
            "Corrected Response: The text you provided is in Arabic, specifically Tunisian Arabic. In formal Arabic, a grammatically correct way to ask \"Hello! How can I help you?\" would be:\n",
            "\n",
            "السلام عليكم! كيف يمكنني مساعدتك؟\n",
            "Generated Question: What is the grammatically correct way to ask \"Hello! How can I help you?\" in formal Arabic?\n",
            "Corrected Response: The text in Arabic is a colloquial greeting and question, primarily used in North Africa, particularly in Tunisia. The corrected version is: \"السلامة! كيفاش مردك؟\" This translates roughly to \"Hello! How is your health?\" or \"How are you doing?\"\n",
            "Generated Question: What is a common colloquial greeting and question used in North Africa, especially in Tunisia, for asking about someone's well-being?\n",
            "Corrected Response: Sure, the corrected text is: \"مرحبا بك! ماذا تحب أن تعرف؟\"\n",
            "Generated Question: What is the corrected text in the passage?\n",
            "Corrected Response: The text is in Arabic, and it actually seems to be correctly spelled and grammatically sound. Here's the text as you provided it:\n",
            "\n",
            "\"ألو سلام! كيفاش نجم نعاونك؟\"\n",
            "\n",
            "In Standard Arabic, the phrase might be written a bit differently, but in colloquial Arabic (like Tunisian or Algerian dialect), it looks perfectly fine. If you need it in Standard Arabic, it could be:\n",
            "\n",
            "\"ألو، السلام عليكم! كيف يمكنني مساعدتك؟\"\n",
            "\n",
            "Would you like more adjustments or translations to a different form of Arabic?\n",
            "Generated Question: What is the main difference between the two versions of the Arabic text provided?\n",
            "Corrected Response: مرحبًا بك! ماذا تريد أن تعرف؟\n",
            "Generated Question: ماذا تود أن تعرف عن خدماتنا؟\n",
            "Corrected Response: Sure, here is the corrected text:\n",
            "\n",
            "\"على العينين والرأس! شنوّة اللي تحب تعرفه؟\"\n",
            "\n",
            "This improves the grammar and ensures accurate spelling in Arabic.\n",
            "Generated Question: What does the Arabic phrase \"على العينين والرأس! شنوّة اللي تحب تعرفه؟\" mean in English?\n",
            "Corrected Response: التصحيح:\n",
            "\n",
            "مرحبًا بالأحباب! شنو يلزمك؟\n",
            "Generated Question: ما هي احتياجاتك التي ترغب في التعبير عنها؟\n",
            "Corrected Response: The text \"نورتنا! كيفاش نجم نعاونك؟\" doesn't have any spelling or grammar mistakes in Arabic. It's a colloquial expression used in some Arabic dialects meaning \"You have enlightened us! How can I help you?\" or \"How can I assist you?\". No corrections are needed.\n",
            "Generated Question: What colloquial Arabic expression is used to convey \"You have enlightened us! How can I help you?\" without any spelling or grammar mistakes?\n",
            "Corrected Response: مرحبًا بك في أليرت! كيف يمكننا خدمتك؟\n",
            "Generated Question: كيف يمكن لأليرت أن يساعدك اليوم؟\n",
            "Corrected Response: The text you provided is in Tunisian Arabic, and its orthography is informal and phonetic. In more standard Arabic (Modern Standard Arabic), it can be written as:\n",
            "\n",
            "‏ما الذي تود السؤال عنه؟\n",
            "\n",
            "However, if you're looking to keep it closer to Tunisian vernacular but in a more standardized writing format, you might write:\n",
            "\n",
            "شنو اللي تحب تسأل عليه؟\n",
            "\n",
            "Both versions are correct, depending on the level of formality and the dialect you wish to use.\n",
            "Generated Question: How do you write \"What do you want to ask about?\" in both Modern Standard Arabic and a more standardized Tunisian Arabic format?\n",
            "Corrected Response: بالطبع! النص يبدو جيدًا وهناك بعض التعديلات البسيطة التي تجعل الجملة أكثر وضوحًا وتقليدية:\n",
            "\n",
            "\"يا هلا باللي جاؤوا! كيف تحب أن أساعدك؟\"\n",
            "\n",
            "أو إذا كان النص موجهًا لشخص واحد:\n",
            "\n",
            "\"يا هلا باللي جا! كيف تحب أن أساعدك؟\"\n",
            "Generated Question: ما هي التعديلات التي تم اقتراحها لتحسين وضوح الجملة عندما تكون موجهة لمجموعة مقابل شخص واحد؟\n",
            "Corrected Response: The text you provided is in Tunisian Arabic, and it appears to be mostly correct for the context it is used in. The phrase \"مرحبا بيك !\" translates to \"Welcome!\" or \"Hello!\" in English, and \"شنوّة اللي تحب تعرفه؟\" translates to \"What would you like to know?\".\n",
            "\n",
            "No corrections are needed for the spelling or grammar. The text is correct as:\n",
            "\n",
            "مرحبا بيك ! شنوّة اللي تحب تعرفه؟\n",
            "Generated Question: What does the phrase \"شنوّة اللي تحب تعرفه؟\" mean in English?\n",
            "Corrected Response: بالتأكيد! النص المعدل سيكون كالتالي:\n",
            "\n",
            "يا هلا بالغالي! شنو يلزمك؟\n",
            "\n",
            "\"شنوّة\" هو تعبير غير شائع في اللغة الفصحى، والصحيح هو \"شنو\".\n",
            "Generated Question: بالتأكيد! السؤال الذي يمكن توليده من النص هو:\n",
            "\n",
            "ما هو التعبير الصحيح في اللغة الفصحى لعبارة \"شنوّة\"؟\n",
            "Corrected Response: النص صحيح ومكتوب بطريقة سليمة. لا يحتاج إلى تصحيح.\n",
            "Generated Question: ما هو تقييمك للنص من حيث الصحة والأسلوب الكتابي؟\n",
            "Corrected Response: صباح الخير! ماذا تريد أن تعرف؟\n",
            "Generated Question: صباح الخير! ما هي الموضوعات التي يمكنني السؤال عنها؟\n",
            "Corrected Response: Sure, I can correct the sentence for you in Arabic. \n",
            "\n",
            "Corrected text:\n",
            "\n",
            "نوّرت الصفحة! كيفاش نجم نعاونك؟\n",
            "\n",
            "If you would like a more formal version, it can be:\n",
            "\n",
            "نوّرت الصفحة! كيف يمكنني مساعدتك؟\n",
            "Generated Question: What is the difference between the two provided versions of the corrected sentence in Arabic?\n",
            "Corrected Response: Sure, here is the corrected version of the text:\n",
            "\n",
            "شنوّة اللي تحب تسأل عليه؟\n",
            "Generated Question: What would you like to ask about?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-84f1f47f7547>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Correct the text and generate a question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mcorrected_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_and_generate_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Print corrected response and question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-84f1f47f7547>\u001b[0m in \u001b[0;36mcorrect_and_generate_question\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Generate a question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mquestion_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Based on the following text, generate a question: {corrected_text}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     question_response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    702\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    703\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         )\n\u001b[0;32m-> 1268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    946\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    982\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    955\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    989\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m         )\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    197\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    114\u001b[0m                 trace.return_value = (\n\u001b[1;32m    115\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    225\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1288\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "# Set the API key\n",
        "client = OpenAI(api_key=\"\")\n",
        "MODEL = \"gpt-4o\"\n",
        "\n",
        "# Load the .jsonl file\n",
        "input_file = '/content/drive/MyDrive/fine_tuning_const/output_data.jsonl'\n",
        "output_file = '/content/drive/MyDrive/fine_tuning_const/corrected2.jsonl'\n",
        "\n",
        "# Function to generate a question based on the assistant's content\n",
        "def generate_question(content):\n",
        "    question_prompt = f\"إعطيني سؤال مرتبط بالمحتوى هذا: {content}\"\n",
        "    question_response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": question_prompt}\n",
        "        ]\n",
        "    )\n",
        "    return question_response.choices[0].message.content.strip()\n",
        "\n",
        "# Process the .jsonl file\n",
        "with open(input_file, 'r', encoding='utf-8') as f, open(output_file, 'w', encoding='utf-8') as out_f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "\n",
        "        # Extract the assistant's response\n",
        "        assistant_response = data['messages'][2]['content']\n",
        "\n",
        "        # Generate a question based on the assistant's content\n",
        "        question = generate_question(assistant_response)\n",
        "\n",
        "        # Update the user content with the generated question\n",
        "        data['messages'][1]['content'] = question\n",
        "\n",
        "        # Write the updated data to the new .jsonl file\n",
        "        out_f.write(json.dumps(data, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(\"Processing complete. Updated file saved as:\", output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOX1hKs9uQer",
        "outputId": "c00335c3-603a-4338-956b-0febf1f71063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complete. Updated file saved as: /content/drive/MyDrive/fine_tuning_const/corrected2.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "# Set the API key\n",
        "client = OpenAI(api_key=\"\")\n",
        "MODEL = \"gpt-4o\"\n",
        "\n",
        "# Load the .jsonl file\n",
        "input_file = '/content/drive/MyDrive/fine_tuning_const/output_data.jsonl'\n",
        "output_file = '/content/drive/MyDrive/fine_tuning_const/fixed_grammar.jsonl'\n",
        "\n",
        "\n",
        "# Function to correct spelling and grammar\n",
        "def correct_text(text):\n",
        "    correction_prompt = f\"صحح الأخطاء الإملائية والنحوية في النص التالي: {text}\"\n",
        "    correction_response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": correction_prompt}\n",
        "        ]\n",
        "    )\n",
        "    return correction_response.choices[0].message.content.strip()\n",
        "\n",
        "# Process the .jsonl file\n",
        "with open(input_file, 'r', encoding='utf-8') as f, open(output_file, 'w', encoding='utf-8') as out_f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "\n",
        "        # Extract system and assistant responses\n",
        "        system_response = data['messages'][0]['content']\n",
        "        assistant_response = data['messages'][2]['content']\n",
        "\n",
        "        # Correct the texts\n",
        "        corrected_system_response = correct_text(system_response)\n",
        "        corrected_assistant_response = correct_text(assistant_response)\n",
        "\n",
        "        # Update the data with corrected responses\n",
        "        data['messages'][0]['content'] = corrected_system_response\n",
        "        data['messages'][2]['content'] = corrected_assistant_response\n",
        "\n",
        "        # Write the updated data to the new .jsonl file\n",
        "        out_f.write(json.dumps(data, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(\"Processing complete. Corrected file saved as:\", output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8Ujn_a8-wUp",
        "outputId": "5b50b697-ad73-4c35-a42d-73bd894ecbe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complete. Corrected file saved as: /content/drive/MyDrive/fine_tuning_const/fixed_grammar.jsonl\n"
          ]
        }
      ]
    }
  ]
}